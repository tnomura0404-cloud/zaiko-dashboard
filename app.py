import streamlit as st
import pandas as pd
from pathlib import Path
from datetime import datetime
from dateutil.relativedelta import relativedelta
import io

# --------------------------------------------------------------------------------
# åˆ†æãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¤‰æ›´ãªã—ï¼‰
# --------------------------------------------------------------------------------
def find_column_name(df_columns, possible_names):
    return next((name for name in possible_names if name in df_columns), None)

def analyze_inventory(src_file, rule_file, history_file):
    # (ã“ã® analyze_inventory é–¢æ•°ã®ä¸­èº«ã¯ã€ä»¥å‰ã®ã‚‚ã®ã¨å…¨ãåŒã˜ã§ã™)
    ws_key = pd.read_excel(rule_file, sheet_name="ã‚­ãƒ¼", header=None, dtype=str).fillna("")
    key_dict = {str(val).strip(): str(ws_key.iloc[0, col_idx]).strip() for col_idx in range(ws_key.shape[1]) for val in ws_key.iloc[1:, col_idx] if str(val).strip()}
    manual_quantities = {}
    if "ãƒªã‚¹ãƒˆ" in pd.ExcelFile(rule_file).sheet_names:
        df_list = pd.read_excel(rule_file, sheet_name="ãƒªã‚¹ãƒˆ", dtype=str)
        quantity_col_name = find_column_name(df_list.columns, ["åŸºæº–æ•°é‡ï¼ˆæ‰‹å‹•ï¼‰", "æ•°é‡"])
        if quantity_col_name:
            manual_quantities = df_list.set_index('å•†å“å')[quantity_col_name].apply(pd.to_numeric, errors='coerce').dropna().astype('Int64').to_dict()
    df_history = pd.DataFrame()
    if history_file is not None:
        try:
            df_history_raw = pd.read_excel(history_file, sheet_name='Data', engine='xlrd')
            column_rename_map = {"è®¢å•å‘è¡Œæ—¥": "order_date", "æ³¨æ–‡ç™ºè¡Œæ—¥": "order_date", "è®¢å•æ•°é‡": "order_quantity", "æ³¨æ–‡æ•°é‡": "order_quantity", "å•†å“åç§°": "product_name"}
            df_history = df_history_raw.rename(columns=lambda c: column_rename_map.get(c, c))
            df_history["order_date"] = pd.to_datetime(df_history["order_date"], errors='coerce')
            df_history["order_quantity"] = pd.to_numeric(df_history["order_quantity"], errors='coerce')
            df_history.dropna(subset=["product_name", "order_date", "order_quantity"], inplace=True)
        except Exception as e:
            st.warning(f"ç™ºæ³¨å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    ws_src = pd.read_excel(src_file, header=10, dtype=str).fillna("")
    inventory_col = find_column_name(ws_src.columns, ['å®¢æˆ·åœ¨åº“', 'åœ¨åº“æ•°é‡', 'åœ¨åº«æ•°é‡'])
    if not inventory_col:
        st.error("ã‚¨ãƒ©ãƒ¼: å…ƒåœ¨åº«è¡¨ã«åœ¨åº«æ•°é‡ã‚’ç¤ºã™åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None, None, None, None
    cols_to_map = {'å•†å“åç§°': 'å•†å“åç§°', inventory_col: 'INVENTORY_LEVEL', 'æœ€ç»ˆå‡ºè·æ—¥': 'æœ€ç»ˆå‡ºè·æ—¥'}
    ws_src.rename(columns={k: v for k, v in cols_to_map.items() if k in ws_src.columns}, inplace=True)
    current_inventory_map = {str(row["å•†å“åç§°"]).strip(): int(pd.to_numeric(row["INVENTORY_LEVEL"], errors='coerce')) for _, row in ws_src.iterrows() if pd.notna(row["å•†å“åç§°"]) and pd.notna(row["INVENTORY_LEVEL"])}
    consumption_dict = {}
    if not df_history.empty:
        df_agg = df_history.groupby('product_name').agg(total_incoming=('order_quantity', 'sum'), first_order_date=('order_date', 'min')).reset_index()
        today = datetime.now()
        for _, row in df_agg.iterrows():
            p_name, total_in, first_date = row['product_name'], row['total_incoming'], row['first_order_date']
            months = max(1, (today.year - first_date.year) * 12 + (today.month - first_date.month))
            current_stock = current_inventory_map.get(p_name, 0)
            total_consumption = total_in - current_stock
            if total_consumption > 0:
                monthly_con = round(total_consumption / months)
                if monthly_con > 0: consumption_dict[p_name] = int(monthly_con)
    low_stock_auto, low_stock_manual, long_term_stock = [], [], []
    one_year_ago = datetime.now() - relativedelta(years=1)
    def assign_brand(product_name):
        return next((bname for key, bname in key_dict.items() if key in str(product_name)), "OTHER")
    ws_src['ãƒ–ãƒ©ãƒ³ãƒ‰'] = ws_src['å•†å“åç§°'].apply(assign_brand)
    df_src_for_report = ws_src.drop_duplicates(subset=['å•†å“åç§°'])
    for _, row in df_src_for_report.iterrows():
        p_name = str(row['å•†å“åç§°']).strip()
        if not p_name: continue
        brand_name = row['ãƒ–ãƒ©ãƒ³ãƒ‰']
        inv_qty, auto_qty, manual_qty = current_inventory_map.get(p_name, 0), consumption_dict.get(p_name), manual_quantities.get(p_name, 0)
        if auto_qty and inv_qty < auto_qty: low_stock_auto.append({"ãƒ–ãƒ©ãƒ³ãƒ‰": brand_name, "å•†å“å": p_name, "åœ¨åº«æ•°": inv_qty, "åŸºæº–æ•°é‡(è‡ªå‹•)": auto_qty, "å·®ã—å¼•ãæ•°é‡": inv_qty - auto_qty})
        if manual_qty and inv_qty < manual_qty: low_stock_manual.append({"ãƒ–ãƒ©ãƒ³ãƒ‰": brand_name, "å•†å“å": p_name, "åœ¨åº«æ•°": inv_qty, "åŸºæº–æ•°é‡(æ‰‹å‹•)": manual_qty, "å·®ã—å¼•ãæ•°é‡": inv_qty - manual_qty})
        ship_date = pd.to_datetime(str(row["æœ€ç»ˆå‡ºè·æ—¥"]).strip(), errors='coerce')
        if pd.notna(ship_date) and ship_date < one_year_ago: long_term_stock.append({"ãƒ–ãƒ©ãƒ³ãƒ‰": brand_name, "å•†å“å": p_name, "æœ€çµ‚å‡ºè·æ—¥": ship_date.date(), "çµŒéæ—¥æ•°": (datetime.now() - ship_date).days, "åœ¨åº«æ•°": inv_qty})
    df_auto = pd.DataFrame(low_stock_auto); df_manual = pd.DataFrame(low_stock_manual); df_long = pd.DataFrame(long_term_stock)
    return ws_src, df_auto, df_manual, df_long

# --- Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®é–¢æ•° ---
def to_excel(df_full, df_auto, df_manual, df_long):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_auto.to_excel(writer, sheet_name='ä¸è¶³åœ¨åº«_è‡ªå‹•', index=False)
        df_manual.to_excel(writer, sheet_name='ä¸è¶³åœ¨åº«_æ‰‹å‹•', index=False)
        df_long.to_excel(writer, sheet_name='é•·æœŸåœ¨åº«', index=False)
        brands = sorted(df_full['ãƒ–ãƒ©ãƒ³ãƒ‰'].unique())
        for brand in brands:
            brand_df = df_full[df_full['ãƒ–ãƒ©ãƒ³ãƒ‰'] == brand].drop(columns=['ãƒ–ãƒ©ãƒ³ãƒ‰'])
            brand_df.to_excel(writer, sheet_name=brand, index=False)
    return output.getvalue()

# --------------------------------------------------------------------------------
# Streamlit UIéƒ¨åˆ†
# --------------------------------------------------------------------------------
st.set_page_config(layout="wide")
st.title('ğŸ“ˆ åœ¨åº«åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰')

# --- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å®šç¾© ---
# ã“ã®ã‚³ãƒ¼ãƒ‰(.py)ã¨åŒã˜å ´æ‰€ã«ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡ã™
BASE_PATH = Path(__file__).resolve().parent
DEFAULT_RULE_FILE = BASE_PATH / "æŒ¯ã‚Šåˆ†ã‘ãƒ«ãƒ¼ãƒ«.xlsx"
DEFAULT_HISTORY_FILE = BASE_PATH / "ç™ºæ³¨å±¥æ­´.xls"

# --- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ ---
# Streamlit Cloudä¸Šã§ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
if not DEFAULT_RULE_FILE.exists():
    st.error("ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã€ŒæŒ¯ã‚Šåˆ†ã‘ãƒ«ãƒ¼ãƒ«.xlsxã€ãŒåŒæ¢±ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop() # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°ã‚¢ãƒ—ãƒªã‚’åœæ­¢
rule_file = DEFAULT_RULE_FILE
history_file = DEFAULT_HISTORY_FILE if DEFAULT_HISTORY_FILE.exists() else None

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ã®UI ---
st.info("ğŸ‘‡ åˆ†æã—ãŸã„ã€Œå…ƒåœ¨åº«è¡¨ã€ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
uploaded_src_file = st.file_uploader("", type=['xlsx', 'xls'], label_visibility="collapsed")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®UI ---
st.sidebar.header("âš™ï¸ è¨­å®š")
st.sidebar.markdown("""
ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¯ã€åŒæ¢±ã•ã‚Œã¦ã„ã‚‹ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
- **æŒ¯ã‚Šåˆ†ã‘ãƒ«ãƒ¼ãƒ«:** `æŒ¯ã‚Šåˆ†ã‘ãƒ«ãƒ¼ãƒ«.xlsx`
- **ç™ºæ³¨å±¥æ­´:** `ç™ºæ³¨å±¥æ­´.xls` (å­˜åœ¨ã™ã‚‹å ´åˆ)

ã“ã‚Œã‚‰ã®ãƒã‚¹ã‚¿ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ãŸã„å ´åˆã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†è€…ã«ã”é€£çµ¡ãã ã•ã„ã€‚
""")

with st.sidebar.expander("ã‚‚ã—ã€ç‰¹åˆ¥ãªãƒ•ã‚¡ã‚¤ãƒ«ã§è©¦ã—ãŸã„å ´åˆã¯ã“ã¡ã‚‰"):
    uploaded_rule_override = st.file_uploader("ç‰¹åˆ¥ãªã€ŒæŒ¯ã‚Šåˆ†ã‘ãƒ«ãƒ¼ãƒ«ã€", type=['xlsx', 'xls'])
    uploaded_history_override = st.file_uploader("ç‰¹åˆ¥ãªã€Œç™ºæ³¨å±¥æ­´ã€", type=['xlsx', 'xls'])
    if uploaded_rule_override:
        rule_file = uploaded_rule_override
    if uploaded_history_override:
        history_file = uploaded_history_override

# --- åˆ†æã¨çµæœè¡¨ç¤º ---
if uploaded_src_file:
    st.success(f"ã€Œ{uploaded_src_file.name}ã€ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    with st.spinner('åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æä¸­...'):
        df_full, df_auto, df_manual, df_long = analyze_inventory(uploaded_src_file, rule_file, history_file)
    
    if df_full is not None:
        st.success('åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼')
        st.header('åˆ†æçµæœ')
        
        excel_data = to_excel(df_full, df_auto, df_manual, df_long)
        st.download_button(
            label="ğŸ“„ Excelå½¢å¼ã§å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=excel_data,
            file_name=f"åœ¨åº«ãƒ¬ãƒãƒ¼ãƒˆ_{datetime.now().strftime('%Y%m%d')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

        tab1, tab2, tab3 = st.tabs([f"ä¸è¶³åœ¨åº«(è‡ªå‹•) ({len(df_auto)})", f"ä¸è¶³åœ¨åº«(æ‰‹å‹•) ({len(df_manual)})", f"é•·æœŸåœ¨åº« ({len(df_long)})"])
        with tab1: st.dataframe(df_auto)
        with tab2: st.dataframe(df_manual)
        with tab3: st.dataframe(df_long.sort_values(by="çµŒéæ—¥æ•°", ascending=False) if not df_long.empty else df_long)

        st.divider()
        st.header('å…¨åœ¨åº«ãƒªã‚¹ãƒˆï¼ˆãƒ–ãƒ©ãƒ³ãƒ‰åˆ¥è©³ç´°ï¼‰')
        brand_list = ["å…¨ãƒ–ãƒ©ãƒ³ãƒ‰è¡¨ç¤º"] + sorted(df_full['ãƒ–ãƒ©ãƒ³ãƒ‰'].unique())
        selected_brand = st.selectbox('è¡¨ç¤ºã—ãŸã„ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:', brand_list)

        if selected_brand == "å…¨ãƒ–ãƒ©ãƒ³ãƒ‰è¡¨ç¤º":
            st.dataframe(df_full)
        else:
            st.dataframe(df_full[df_full['ãƒ–ãƒ©ãƒ³ãƒ‰'] == selected_brand])